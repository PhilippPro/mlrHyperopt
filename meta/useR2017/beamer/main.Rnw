%!TEX program = xelatex
\documentclass[10pt]{beamer}

%\usepackage{handoutWithNotes}
%\pgfpagesuselayout{4 on 1 with notes}[a4paper,border shrink=5mm]

%own packages
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{xspace}
\usepackage{xcolor}
\usepackage{textcomp}
\mathtoolsset{showonlyrefs}
\usepackage{grffile}
\usepackage{csquotes}
\usepackage[english]{babel}
\usepackage{caption}
\usepackage{graphicx} %trim for includegraphics
\usepackage{siunitx} % \SI for units
\usepackage{booktabs}
\usepackage{fancybox}


%TikZ stuff
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{chains, positioning, arrows}

%beamer template
%\usepackage{handoutWithNotes}
%\pgfpagesuselayout{4 on 1 with notes}[a4paper,border shrink=5mm]

%bib handling
\usepackage[backend=biber,style=authoryear,bibencoding=utf8, maxcitenames=1]{biblatex}
\addbibresource[datatype=bibtex]{literature.bib}
\DeclareCiteCommand{\xfootcite}[\mkbibfootnote]
  {\usebibmacro{prenote}}
  {\usebibmacro{citeindex}%
   \setunit{\addnbspace}
   \printnames{labelname}%
   \setunit{\labelnamepunct}
  \printfield[citetitle]{title}%
   \newunit
   \printfield{year}
}{\addsemicolon\space}{\usebibmacro{postnote}}

%theme adjustements
\usetheme[block = fill, progressbar = frametitle, ]{metropolis}
\definecolor{TuGreen}{RGB}{132,184,24}
\definecolor{TuGreen40}{RGB}{211,227,175}
\setbeamercolor{title separator}{fg = TuGreen}
\setbeamercolor{progress bar}{fg = TuGreen, bg = TuGreen40}
\setbeamertemplate{frame footer}{Jakob Richter (TU Dortmund)}
\setbeamersize{text margin left=1cm,text margin right=1cm}
\setbeamerfont{title}{size=\large}%
%\usefonttheme[onlymath]{serif}

\newcommand{\rb}[1]{\texttt{rosenbrock}$(#1)$}
\newcommand{\boha}[1]{\texttt{bohachevsky}$(#1)$}
\newcommand{\ack}[1]{\texttt{ackley}$(#1)$}
\newcommand{\ras}[1]{\texttt{rastrigin}$(#1)$}

\setlength{\topsep}{0pt}
\setlength{\parskip}{0pt}
\setlength{\partopsep}{1pt}

%set title
\title[mlrHyperopt]{mlrHyperopt: Effortless and collaborative hyperparameter optimization experiments}
\date{\today}
\author[Jakob Richter]{Jakob~Richter}
\institute{Faculty of Statistics, TU Dortmund University}

\titlegraphic{\raisebox{0.5cm}{\includegraphics[height=0.5cm]{assets/tud_logo_pantone}}\hfill\includegraphics[height=1cm]{assets/3zeilig_links_en}}

\begin{document}

<<setup, include=FALSE>>=
library(knitr)
library(pander)
library(xtable)
library(reshape2)
library(ggplot2)
library(stringi)
library(magrittr)
library(data.table)
library(BBmisc)
options(formatR.arrow=TRUE, width=120)
opts_chunk$set(
  fig.path='figure/',
  fig.align='center',
  fig.show='hold',
  fig.lp='fig:',
  fig.width = 8,
  fig.height = 5.5,
  size='small',
  message=FALSE,
  warning=FALSE,
  cache=TRUE,
  cache.path='cache/'
  )

if(getwd() %>% stri_endswith_fixed("mlrHyperopt")) {
  setwd(file.path(getwd(), "meta", "useR2017", "beamer"))
}

myrank = function(x, ties.method) {
  ranks = rank(x, na.last = TRUE, ties.method = ties.method)
  ranks[is.na(x)] = max(ranks)
  ranks
}

trans_theme = theme(
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    panel.background = element_rect(fill=NA),
    plot.background = element_rect(fill=NA),
    legend.background = element_rect(fill=NA)
)
@

\maketitle

\begin{frame}{Contents}
  \begin{enumerate}
    \item Motivation for \texttt{caret}\footnote{\url{https://topepo.github.io/caret}} Users
    \item Motivation for \texttt{mlr}\footnote{\url{https://mlr-org.github.io/mlr}} Users
    \item Website and API
    \item Parameter Tuning
    \item Lessons learned
  \end{enumerate}
\end{frame}

\section{Motivation}

\begin{frame}[fragile]{caret}

\texttt{caret} automatically performs a grid search for all learners.

<<caret1, message=FALSE>>=
library(caret)
system.time({m.c = train(iris[,1:4], iris[,5], method = "rf")})
system.time({m.r = randomForest(iris[,1:4], iris$Species)})
@

How to find out what is going on?

<<caret2>>=
m.c$results
@
\end{frame}

\begin{frame}[fragile]{caret}
Can I find out in advance which parameters will be tuned? \\
\vspace{0.5em}
\begin{overprint}
  \onslide<1>
  \texttt{modelLookup("rf")} gives some information.
  <<caretModelLookup, size='scriptsize'>>=
modelLookup("rf")
@
  \onslide<2>
  \begin{figure}
    \shadowbox{\includegraphics[width=0.8\linewidth]{assets/caret_screen_model_source.png}}
    \caption*{\url{http://github.com/topepo/caret/blob/master/models/files} reveals all details.}
  \end{figure}
\end{overprint}
\end{frame}

\begin{frame}[fragile]{caret: gbm}
Extract from \texttt{models/files/gbm.R}:
<<caretGbmStrangeGrid, eval = FALSE, size='scriptsize'>>=
out <- expand.grid(
  interaction.depth = seq(1, len), #<- parameter range depends on tuning budget
  n.trees = floor((1:len) * 50), #<- ..
  shrinkage = .1,
  n.minobsinnode = 10)
# ...
# Random Search
out <- data.frame(
  n.trees = floor(runif(len, min = 1, max = 5000)),
  interaction.depth = sample(1:10, replace = TRUE, size = len),
  shrinkage = runif(len, min = .001, max = .6),
  n.minobsinnode = sample(5:25, replace = TRUE, size = len) )
    out <- out[!duplicated(out),]
@
\end{frame}

\begin{frame}[fragile]{mlr}

\texttt{mlr} provides parameter definitions for all learners.
<<mlrLearner, size='scriptsize'>>=
library(mlr)
lrn = makeLearner("classif.randomForest")
filterParams(getParamSet(lrn), tunable = TRUE)
@
But \texttt{ParamSets} are unconstrained and include possibly unimportant parameters.
\end{frame}

\begin{frame}[fragile]{mlr}

Necessary to define own \texttt{ParamSets} for tuning:

<<paramSet1, message=FALSE>>=
ps = makeParamSet(
  makeIntegerParam("mtry", lower = 1, upper = 4),
  makeIntegerParam("nodesize", lower = 1, upper = 10)
)
tuneParams(lrn, iris.task, cv10, measures = acc,
  par.set = ps, makeTuneControlGrid(resolution = 3L))
@

\end{frame}

\begin{frame}[fragile]{caret}

Deviate from the defaults in \texttt{caret}:

<<caretDeviate, message=FALSE>>=
grid = expand.grid(mtry = 2:4, nodesize = c(1,5,10))
m = caret::train(iris[,1:4], iris[,5],
  method = "rf", tuneGrid = grid)
@

It seems you have to write you own custom method\footnote{\url{https://stackoverflow.com/questions/38625493/tuning-two-parameters-for-random-forest-in-caret-package}}.
\end{frame}

\begin{frame}{mlr vs. caret}
\begin{block}{In caret...}
  \begin{itemize}
    \item[$+$] tuning is the default.
    \item[$+$] tuning with defaults is easy.
    \item[$-$] deviating from defaults is a hassle and needs expert knowledge.
  \end{itemize}
\end{block}

\begin{block}{In mlr...}
  \begin{itemize}
    \item[$+$] train works like the default of the package.
    \item[$-$] tuning needs expert knowledge.
    \item[$+$] deviating from defaults is easy.
  \end{itemize}
\end{block}

To solve this problem in \texttt{mlr} we want to share the expert knowledge with...
\end{frame}

\section{mlrHyperopt}

\begin{frame}{mlrHyperopt}

\texttt{mlrHyperopt} enables access to a web database of Parameter Configurations for many machine learning methods in R.

\begin{block}{Why an online database?}
  \begin{itemize}
    \item Defaults in packages will always be controversial.
    \item Knowledge changes over time but \texttt{R} packages have to maintain reproducibility.
    \item Defaults differ for different scenarios. (data set size \emph{etc.})
  \end{itemize}
\end{block}

\end{frame}

\begin{frame}{mlrHyperopt: ParConfigs}

\texttt{mlrHyperopt} stores tuning parameters in \texttt{ParConfigs}:

\begin{itemize}
  \item \emph{Parameter Set} of tunable parameters
  \item fixed \emph{Parameter Values} to overwrite defaults
  \item associated learner and note
\end{itemize}

\begin{block}{Features of the Parameter Set\footnote{\url{https://github.com/berndbischl/ParamHelpers}}:}
  \begin{itemize}
    \item Parameter values can be: real-valued, integer, discrete, logical, \ldots
    \item Parameters can have:
    \begin{itemize}
      \item transformations (to account non-uniform distribution of interesting regions)
      \item requirements on other parameters (to represent hierarchical structures)
    \end{itemize}
    \item Bounds and defaults can depend on the task size, number of features, \emph{etc.}
  \end{itemize}
\end{block}

\end{frame}

\section{API Examples}

\begin{frame}{Web Interface}

\begin{figure}[h]
  \shadowbox{\includegraphics[width=\linewidth]{assets/mlrHyperopt_screen_parconfigs.png}}
  \caption*{Overview of all \texttt{ParConfigs} uploaded to \url{http://mlrhyperopt.jakob-r.de/parconfigs}}
\end{figure}

\end{frame}

\begin{frame}[fragile]{API: Download and Use ParConfigs}
Tune the parameters for the \texttt{ranger} Random Forest with \texttt{mlr}\footnote{\url{http://mlr-org.github.io/mlr-tutorial/devel/html/tune/}}.
<<apiDownload, message=FALSE, size='scriptsize'>>=
library(mlrHyperopt)
lrn = makeLearner("classif.ranger")
(pc = downloadParConfigs(learner.class = getLearnerClass(lrn)))
ps = getParConfigParSet(pc[[1]])
ps = evaluateParamExpressions(ps, dict = getTaskDictionary(iris.task))
lrn = setHyperPars(lrn, par.vals = getParConfigParVals(pc[[1]]))
tuneParams(lrn, iris.task, resampling = cv10, par.set = ps,
  measures = acc, control = makeTuneControlRandom(maxit = 10))
@
\end{frame}

\begin{frame}[fragile]{API: Upload ParConfigs}

\begin{figure}
  \center
  \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
    circ/.style={circle,draw,font=\scriptsize},
    rect/.style={rectangle,draw,font=\scriptsize}]
    \node[draw=none,fill=none] (20) at (0, 0) {$\mathcal X$};
    \node[circ]  (8) at (1, -1.1) {$C$};
    \node[circ]  (9) at(1, 0.5) {\emph{kernel}};
    \node[rect] (17) at (2.5, 0){rbfdot};
    \node[rect] (10) at (2.5, 1.1){polydot};
    \node[circ] (11) at(4, 0) {\emph{sigma}};
    \node[circ] (degree) at(4, 1.1) {\emph{degree}};
    \node[rect] (15) at (5.5, -1.1) {$[2^{-5}, 2^{5}]$};
    \node[rect] (16) at (5.5, 0) {$[2^{-10}, 2^{10}]$};
    \node[rect] (degree2) at (5.5, 1.1) {$[1, \ldots, 5]$};
    \path[every node/.style={font=\sffamily\small}]
    (20) edge node {}(8)
    edge node {}(9)
    (8) edge node {}(15)
    (9) edge node {}(10)
    edge node {}(17)
    (17) edge node {}(11)
    (11) edge node {}(16)
    (10) edge node {}(degree)
    (degree) edge node {}(degree2);
  \end{tikzpicture}
  \caption*{Dependent search space for the tuning of a support vector machine.}
  \label{fig:svm_hyperparameters}
\end{figure}

<<apiUpload, message=FALSE, size='scriptsize', eval=FALSE>>=
ps = makeParamSet(
  makeDiscreteParam("kernel", c("rbfdot", "polydot")),
  makeNumericParam("C", -5, 5, trafo = function(x) 2^x),
  makeNumericParam("sigma", lower = -10, upper = 10,
    trafo = function(x) 2^x, requires = quote(kernel == "rbfdot")),
  makeNumericParam("degree", lower = 1, upper = 5,
    requires = quote(kernel == "polydot"))
)
pc = makeParConfig(ps, learner.name = "ksvm")
uploadParConfig(pc)
## [1] "23"
@
\end{frame}

\begin{frame}[fragile]{Bonus: Use ParConfigs in caret}

With the following \texttt{ParamHelpers} functions we can generate grids for \texttt{caret}
\begin{itemize}
  \item \texttt{generateGridDesign}
  \item \texttt{generateRandomDesign}
  \item \texttt{generateDesign} (Latin Hypercube Sample)
  \item \texttt{generateDesignOfDefaults} (to be used in combination)
\end{itemize}
<<apiCaret, message=FALSE, size='scriptsize', warning=FALSE>>=
pc = downloadParConfigs(learner.name = "nnet")
grid = generateRandomDesign(n = 10L, par.set = pc[[1]]$par.set,
  trafo = TRUE)
tr = caret::train(iris[,1:4], iris[,5], method = "nnet",
  tuneGrid = grid, trace = FALSE)
tr$bestTune
@
\end{frame}

\section{Tuning with \texttt{mlrHyperopt}}

\begin{frame}[fragile]{Tuning parameters with \texttt{mlrHyperopt}}
A heuristic decides for tuning method:
\begin{block}{Tuning Methods:}
  \begin{itemize}
    \item \textbf{grid search:} 1 parameter, 2 mixed parameters
    \item \textbf{random search:} $>2$ mixed parameters
    \item \textbf{Bayesian optimization with \texttt{mlrMBO}\footnote{https://mlr-org.github.io/mlrMBO/}:} all parameters numeric
  \end{itemize}
\end{block}
Default parameter sets from \texttt{mlrHyperopt} are used:
<<tuneMlrHyperopt, warning=FALSE, message=FALSE>>=
(h.res = hyperopt(task = iris.task, learner = "classif.ksvm"))
m = mlr::train(h.res$learner, iris.task)
@
\end{frame}

<<readBenchmarkResults, include=FALSE>>=
res = readRDS("../../res5.rds")

# merge learner names
lrns = data.frame(
  mlr =   c("ksvm",      "randomForest", "glmnet", "rpart", "nnet", "xgboost", "extraTrees"),
  caret = c("svmRadial", "rf",           "glmnet", "rpart", "nnet", "xgbTree", "extraTrees")
)

# which caret methods use the submodel trick:
caret.submodel = c("ada", "AdaBag", "AdaBoostM1", "bagEarth", "blackboost", "blasso", "BstLm", "bstSm", "bstTree", "C50", "C50Cost", "cubist", "earth", "enet", "foba", "gamboost", "gbm", "glmboost", "glmnet", "kernelpls", "lars", "lars2", "lasso", "lda2", "leapBackward", "leapForward", "leapSeq", "LogitBoost", "pam", "partDSA", "pcr", "PenalizedLDA", "pls", "relaxo", "rfRules", "rotationForest", "rotationForestCp", "rpart", "rpart2", "rpartCost", "simpls", "spikeslab", "superpc", "widekernelpls", "xgbTree")
intersect(lrns$caret, caret.submodel)

lrns2 = as.data.table(lrns)
lrns2 = plyr::rename(lrns2, c(caret = "learner"))
res = merge(res, lrns2, all.x = TRUE, by = "learner")
res[!is.na(mlr), learner := mlr, ]
res[learner %in% lrns2[learner %in% caret.submodel, mlr], learner := stri_paste(learner,'*')]

# remove not working combinations (including possible time outs)
table(res[is.na(measure) & budget == 10,]$problem, res[is.na(measure) & budget == 10,]$learner)
res = res[, exclude := (learner %in% c("nnet", "extraTrees", "randomForest", "xgboost") & problem == "Internet-Advertisements") |
          (learner %in% c("extraTrees", "glmnet", "ksvm", "xgboost") & problem == "monks-problems-2") |
          (learner %in% c("extraTrees", "xgboost") & problem == "JapaneseVowels") ]

# punish not done
res[is.na(measure), measure := 0]

# naming and units
res[, algorithm := plyr::revalue(algorithm, c(mlrDefault = "default"))]
res[algorithm == "default", budget := 1]
res[, Method := algorithm]
res[algorithm == "caret", Method := paste(algorithm,search)]
res[, Method := factor(Method)]
res[, Combination := sprintf("%s tuned with %s", learner, Method)]
res[, budget := as.factor(budget)]
res$time = as.numeric(res$time, units = "secs")
res[, case := paste0(problem, ": ", learner)]
@
<<DownloadOMLTasksForInfos, include=FALSE>>=
# OpenML Datasets
library(OpenML)
random.task.ids = c(18L, 9914L, 3896L, 3903L, 3510L) #, 28L, 9986L, 43L, 10101L, 14970L)
tunable.task.ids = c(9914L, 3883L, 3493L, 34536L, 9970L)
tunable.task.ids = setdiff(tunable.task.ids, random.task.ids)
oml.tasks = lapply(sort(c(random.task.ids, tunable.task.ids)), getOMLTask)
@

\begin{frame}{Benchmark}
OpenML\footnote{\url{https://www.openml.org/}} Data Sets
\vspace{0.5em}
<<OpenMLOverview, echo=FALSE, results='asis'>>=
tmp = data.frame(
  OpenML_ID = extractSubList(oml.tasks, "task.id"),
  Name = extractSubList(oml.tasks, c("input", "data.set", "desc", "name")),
  p = viapply(oml.tasks, function(x) as.integer(length(x$input$data.set$colnames.new) - 1)),
  n = viapply(oml.tasks, function(x) nrow(x$input$data.set$data))
)
tmp %>% xtable() %>% print(booktabs = TRUE, latex.environments=c("center", "footnotesize"), include.rownames = FALSE)
@
\vspace{1em}
Algorithms: \texttt{caret} with \emph{grid} and \emph{random} search and \texttt{mlrHyperopt}. Each with a budget of $10$ and $50$ CV10-evaluations.
\end{frame}

\begin{frame}{All Results}
<<results1, echo=FALSE, fig.width=14, fig.height=10.5>>=
tmp = copy(res)
tmp[exclude == TRUE, measure := 0]
g = ggplot(data = tmp[budget %in% c(1,10)], aes(x = Method, y = measure, color = Method))
g = g + geom_boxplot() + facet_wrap("case", scales = "free", ncol = length(unique(tmp$learner)))
g = g + theme(axis.text.x=element_blank(), legend.position="bottom") + ylab("accuracy")
g
@
\end{frame}

<<makeDataWithDefaultInAllBudgets, include=FALSE>>=
tmp.default = res[algorithm == "default"]
tmp = res[algorithm != "default"]
tmp.default$budget = NULL
tmp.default = merge(tmp.default, data.table(budget = unique(tmp$budget), algorithm = "default"), by = "algorithm", all.y = TRUE, allow.cartesian = TRUE)
res.def = rbind(tmp, tmp.default)
res.def[, budget := factor(budget)]
@


\begin{frame}{Performance: Dominance}
<<resultsDominanceTested, include=FALSE>>=
combs = expand.grid(MethodA = unique(res.def$Method), MethodB = unique(res.def$Method), budget = unique(res.def$budget))
beat.test.fun = function(x.budget, x.a, x.b) {
  tres = res.def[exclude == FALSE & budget == x.budget, {
    x = measure[Method==x.a]
    y = measure[Method==x.b]
    if (all(x == y)) 1 else wilcox.test(x = x, y = y, paired = TRUE, alternative = "greater")$p.value
  }, by = .(case)]$V1
  mean(!is.na(tres) & tres <= 0.05)
}
beat.test.mat = Map(beat.test.fun, x.budget = combs$budget, x.a = combs$MethodA, x.b = combs$MethodB)
beat.test.mat = split(unlist(beat.test.mat), combs$budget)
beat.test.mat = lapply(beat.test.mat, function(x) {
  ms = unique(res.def$Method)
  matrix(x, nrow = length(ms), dimnames = list(ms,ms))
})
@
\begin{overprint}
\onslide<1>
Performance with a \alert{budget of 10} 10CV-Evaluations.
<<resultsDominanceTested_budget10, echo = FALSE, results='asis'>>=
xtable(beat.test.mat[[1]], align = "l|rrrr") %>% print.xtable(booktabs = TRUE)
@
\onslide<2>
Performance with a \alert{budget of 50} 10CV-Evaluations.
<<resultsDominanceTested_budget50, echo = FALSE, results='asis'>>=
xtable(beat.test.mat[[2]], align = "l|rrrr") %>% print.xtable(booktabs = TRUE)
@
\end{overprint}

\vspace{1em}
The table gives the fractions of instances where $H_0: acc_A \leq acc_B$ is rejected by the paired \emph{Wilcoxon}-test to level $\alpha = 0.05$. $A$ column, $B$ rows.\\
\vspace{0.5em}
\emph{i.e.:} \texttt{mlrHyperopt} is significantly better than the default settings in \only<1>{\Sexpr{sprintf("%.0f", beat.test.mat[[1]]["mlrHyperopt","default"] * 100)}}\only<2>{\Sexpr{sprintf("%.0f", beat.test.mat[[2]]["mlrHyperopt","default"] * 100)}}\% of the cases.
\end{frame}

\begin{frame}{Which Learner Tuner Combination is a Good Choice?}
<<testEqualToLeader, echo=FALSE, fig.width=8.5, fig.height=5>>=
tmp = copy(res.def)
tmp = tmp[exclude == FALSE,]
tmp = tmp[, {
  # get averaged measures
  mySD = copy(.SD)
  averagedSD = mySD[, list(mean.measure = mean(measure)) , by = .(learner, Method, Combination)]
  # get measures per fold for the learner Method combination with the top mean
  topSD = merge(mySD, averagedSD[which.max(mean.measure), .(learner, Method, Combination)])
  topmeasure = topSD$measure
  # test that against all combinations (small p.value means the combination is significantly worse than the best performing one)
  mySD[, list(p.value = wilcox.test(x = measure, y = topmeasure, alternative = "less", paired = TRUE)$p.value, top.com = topSD$Combination[1], mean.measure = mean(measure)) , by = .(learner, Method, Combination)]
} , by = .(problem, budget)]
tmp[is.nan(p.value), p.value := 1]
# tmp[, equal.to.first := p.value <= 0.05]
# tmp = tmp[, mean(equal.to.first), by = .(learner, Method, Combination)]
# tmp = tmp[, Combination := forcats::fct_reorder(Combination, V1)]
# g = ggplot(tmp, aes(y = V1, x = Combination, color = Method, ymax = V1))
# g + geom_point(size = 3) + coord_flip() + geom_linerange(ymin = 0, size = 1.5, mapping = aes(ymax = V1, linetype = learner)) + theme(legend.position = "bottom") + ylab("Fraction")
g = ggplot(tmp, aes(y = Combination, x = problem, fill = p.value))
g + geom_tile() + scale_fill_gradient2(low = "red", mid = "white", high ="green", midpoint = 0.1)
@
Results for the paired \emph{Wilcoxon}-test $H_0: acc_A \leq acc_{\ast}$ with $acc_{\ast}$ denoting the accuracy of the best performing algorithm.
\end{frame}

\section{Lessons Learned}

\begin{frame}{Lessons Learned}

\begin{itemize}
  \item Parameter Tuning is only beneficial on some data and for some methods.
  \item \texttt{caret}s grid search has performance problems on big data sets (ksvm, nnet).
  \item \texttt{caret}s grid search sub model trick is beneficial (glmnet).
  \item For \texttt{caret}s grid search the parameter space expands with increasing \texttt{tuneLength}.
  \item \texttt{mlrHyperopt}s Bayesian optimization causes considerable overhead for small data sets.
  \item The benchmark indicates that \emph{random search} is better than the grid search.
\end{itemize}

\end{frame}

\begin{frame}{\texttt{mlrHyperopt}}

  \begin{block}{Benefits}
    \begin{itemize}
      \item Transparent and reproducible benchmarks in combination with \emph{OpenML}: \\
      \emph{e.g.} Tune ml method A on parameter space with id 123 on Open ML Task 456.
    \end{itemize}
  \end{block}

  \begin{block}{Outlook}
    \begin{itemize}
      \item Implement voting system / advanced statistics
    \end{itemize}
  \end{block}

\begin{minipage}[t]{0.75\linewidth}
\vspace{-1em}
  Find us on GitHub
  \begin{itemize}
    \item \url{github.com/jakob-r/mlrHyperopt}
    \item \url{github.com/mlr-org/mlr}
  \end{itemize}
\end{minipage}
\begin{minipage}[t]{0.14\linewidth}
\vspace{0pt}
  \includegraphics[width = \linewidth]{assets/mlrLogo_blue_566x256}
  \vspace{0.1cm}
  \includegraphics[width = 0.66\linewidth]{assets/GitHub-Mark}
\end{minipage}

\end{frame}
\end{document}
